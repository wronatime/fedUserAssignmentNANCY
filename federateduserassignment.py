# -*- coding: utf-8 -*-
"""FederatedUserAssignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12w2LJtjkJWP3cFgOMcNSmRI7c1RC_S50

# Import Section
"""

import numpy as np
import matplotlib.pyplot as plt
import time

import tensorflow as tf
import tensorflow.keras as keras

from tensorflow.keras.optimizers import Adam

"""# D3QN Agent

## Neural Network
"""

class DuelingDeepQNetwork(keras.Model):

  def __init__(self, n_actions, fc1_dims, fc2_dims):

    super(DuelingDeepQNetwork, self).__init__()
    self.dense1 = keras.layers.Dense(fc1_dims, activation = 'relu')
    self.dense2 = keras.layers.Dense(fc2_dims, activation = 'relu')
    self.V = keras.layers.Dense(1, activation=None)
    self.A = keras.layers.Dense(n_actions, activation=None)

  def call(self, state):

    x = self.dense1(state)
    x = self.dense2(x)
    V = self.V(x)
    A = self.A(x)

    Q = (V + (A - tf.math.reduce_mean(A, axis=1, keepdims=True)))

    return Q

  def advantage(self, state):

    x = self.dense1(state)
    x = self.dense2(x)
    A = self.A(x)

    return A

"""## Replay Buffer"""

class ReplayBuffer:
  def __init__(self, max_size, input_shape):

    self.mem_size = max_size
    self.mem_cntr = 0

    self.state_memory = np.zeros((self.mem_size, *input_shape),
                                 dtype=np.float32)
    self.new_state_memory = np.zeros((self.mem_size, *input_shape),
                                 dtype=np.float32)

    self.action_memory = np.zeros(self.mem_size,
                                 dtype=np.int32)
    self.reward_memory = np.zeros(self.mem_size,
                                 dtype=np.float32)
    self.terminal_memory = np.zeros(self.mem_size,
                                 dtype=bool)

  def store_transition(self, state, action, reward, state_, done):

    index = self.mem_cntr % self.mem_size
    self.state_memory[index] = state
    self.new_state_memory[index] = state_
    self.action_memory[index] = action
    self.reward_memory[index] = reward
    self.terminal_memory[index] = done

    self.mem_cntr += 1

  def sample_buffer(self, batch_size):

    max_mem = min(self.mem_cntr, self.mem_size)
    batch = np.random.choice(max_mem, batch_size, replace=False)
    states = self.state_memory[batch]
    states_ = self.new_state_memory[batch]
    actions = self.action_memory[batch]
    rewards = self.reward_memory[batch]
    dones = self.terminal_memory[batch]

    return states, actions, rewards, states_, dones

"""## Agent"""

class Agent:

  def __init__(self, lr, gamma, n_actions, batch_size,
               input_dims, mem_size=1000000, fc1_dims=128, fc2_dims=128,
               replace=100):

    self.action_space = [i for i in range(n_actions)]
    self.gamma = gamma
    self.replace = replace
    self.batch_size = batch_size
    self.learn_step_counter = 0
    self.memory = ReplayBuffer(mem_size, input_dims)
    self.q_eval = DuelingDeepQNetwork(n_actions, fc1_dims, fc2_dims)
    self.q_next = DuelingDeepQNetwork(n_actions, fc1_dims, fc2_dims)

    self.q_eval.compile(optimizer=Adam(learning_rate=lr),
                        loss='mean_squared_error')
    self.q_next.compile(optimizer=Adam(learning_rate=lr),
                        loss='mean_squared_error')

    # Initialize DQN Networks
    dummy_input = tf.random.normal((1, *input_dims))  # Create a random input tensor
    self.q_next(dummy_input)  # Call the model once with dummy input
    self.q_eval(dummy_input)  # Call the model once with dummy input


  def store_transition(self, state, action, reward, new_state, done):
    self.memory.store_transition(state, action, reward, new_state, done)

  def choose_action(self, observation, epsilon):

    if np.random.random() < epsilon:
      action = np.random.choice(self.action_space)
    else:
      state = np.array([observation])
      actions = self.q_eval.advantage(state)
      action = tf.math.argmax(actions, axis=1).numpy()[0]
    return action

  def learn(self):
    if self.memory.mem_cntr < self.batch_size:
      return

    if self.learn_step_counter % self.replace == 0:
      '''
      Copy weights each 100 learning steps
      '''

      print("... Copying weights...")
      self.q_next.set_weights(self.q_eval.get_weights())

    states, actions, rewards, states_, dones = \
              self.memory.sample_buffer(self.batch_size)
    q_pred = self.q_eval(states)
    q_next = self.q_next(states_)
    # changing q_pred doesn't matter because we are passing states to the train
    # function anyway
    q_target = q_pred.numpy()
    max_actions = tf.math.argmax(self.q_eval(states_),axis=1)

    for idx, terminal in enumerate(dones):
      q_target[idx, actions[idx]] = rewards[idx] + \
      self.gamma*q_next[idx, max_actions[idx]]*(1-int(dones[idx]))

    self.q_eval.train_on_batch(states, q_target)

    self.learn_step_counter += 1

"""# Federated Averaging"""

import tensorflow as tf
import numpy as np

def federated_average(models):
    """Computes the mean of the model weights and updates all models with the average."""

    # Extract weights from all models
    weights = [model.get_weights() for model in models]

    # Compute the mean of each weight tensor
    avg_weights = [np.mean(w, axis=0) for w in zip(*weights)]

    # Assign averaged weights to all models
    for model in models:
        model.set_weights(avg_weights)

"""# Cellular Network Environment"""

class CellularNetworkEnv:
    def __init__(self, BS_power = 10, num_users=10, bandwidth_mhz=50,
                 total_PRBS=270):

        '''
        Input Arguments:
            BS_power  : transmitting power of each BSs, in Watt
            num_users : number of mobile devices to be compensated
            bandwidth_mhz : channel bandwidth used by the BS (do not modify it!)
            total_PRBS    : total number of PRBS, it depends on the 5G-NR specs (do not modify it!)

            For 15 kHz subcar spacing and BW = 50 MHz, we have 270 PRBs

        '''

        '''
        Geometry for the path loss
        '''
        self.W = 20    # street width
        self.h = 20    # avg building height

        self.h_BS = 25   # BS height
        self.h_UE = 1.5  # UE height

        '''
        For the geometry of cells, look at the scenario in Overleaf
        '''

        self.Kelvin = 293   # 20 Â°C

        self.num_BS = 4                   # 4 base station, each one handling 3 cells

        self.num_cells = 6                # 6 cells can compensate the sleeping one

        self.n_actions = self.num_cells   # we have as many actions as cells

        self.BS_rotta = (0,1500)
        self.hexagon_size = 700

        self.cells, self.vertici = self.create_cells()

        # Center of the faulty hexagon
        self.center = np.zeros(2)
        self.center[0] = self.vertici[0][1][0] + self.hexagon_size
        self.center[1] = self.vertici[0][1][1]

        self.BS_pos = []

        self.BS_pos.append(self.cells[2]['BS_position'])
        self.BS_pos.append(self.cells[0]['BS_position'])
        self.BS_pos.append(self.cells[4]['BS_position'])
        self.BS_pos.append(self.cells[5]['BS_position'])

        self.colors = []

        self.colors.append(self.cells[2]['color'])
        self.colors.append(self.cells[0]['color'])
        self.colors.append(self.cells[4]['color'])
        self.colors.append(self.cells[5]['color'])

        # Users' random positions within the faulty cell
        self.current_user = 0  # Tracks the current user requesting service

        self.num_users = num_users

        # Plot users as simple grey points
        self.users = self.random_points_in_hexagon()

        self.user_assignments = []

        # Base station parameters
        self.tx_power_dbm = 10 * np.log10(BS_power * 1000)  # T_power in dBm


        # Params for gains
        self.G_max =  18     # dBi
        self.HPBW_h = 65     # degrees
        self.SSL_h =  30     # dB

        # User gain
        self.gain_rx_db = 0

        self.freq_GHz = 3.5                   # 3.5 GHz - the frequency used by WindTRE Italy
        self.freq_hz = self.freq_GHz*(10**9)  # from GHz to Hz
        # PRB allocation
        self.total_prbs = total_PRBS
        self.bandwidth_mhz = bandwidth_mhz

        self.subcar = 12 # 12 subcarriers per each PRB
        self.subcar_freq = 15000 # 15 kHz subcarrier spacing
        self.prb_bandwidth_hz = self.subcar * self.subcar_freq

        # Cells' loads - initialize randomly accordin to a gaussian
        # Parameters
        self.mu = 0.2       # Mean
        self.sigma = 0.05   # Standard deviation

        # Extract 6 Gaussian random samples
        self.bs_load = np.random.normal(self.mu, self.sigma, self.n_actions)

        # User QoS requirements (randomly assigned)
        self.datarates = [1, 5, 10]  # Mbps
        self.user_qos = np.random.choice(self.datarates, self.num_users)

        # Map qos values to corresponding indices - to be used as first observation
        self.qos_levels = np.array([self.datarates.index(q) for q in self.user_qos])

        self.ter = False
        self.tru = False

        '''
        Limits on RSRP (empirically found)
        '''
        self.RSRP_min = -119.5
        self.RSRP_max = -30

        # RSRP states
        self.RSRPs = np.array([self.compute_RSRP(bs_id, self.current_user) for bs_id in range(self.n_actions)])
        self.norm_RSRPs = self.normalize_RSRP(self.RSRPs)

        '''
        There are 13 states
              1 QoS
              6 RSRPs towards the 6 cells
              6 Loads towards the 6 cells
        '''
        self.n_states = 13

    def plot_hexagon_D3QN(self):

      south_users = []

      # Plotting with matplotlib.
      fig, ax = plt.subplots(figsize=(5.1,6))
      plt.grid(False)

      vertici = self.vertici

      # Create Polygon patches from the vertices.
      faulty = plt.Polygon(vertici[0], closed=True, facecolor='red',
                          alpha=0.3,
                          edgecolor='black',
                          linewidth=2)
      nord = plt.Polygon(vertici[1], closed=True,fill=None, edgecolor='black', linewidth=2)
      nord_est = plt.Polygon(vertici[2], closed=True,fill=None,
                            edgecolor='black', linewidth=2)
      nord_ovest = plt.Polygon(vertici[3], closed=True, fill=None, edgecolor='black', linewidth=2)
      sud = plt.Polygon(vertici[4], closed=True, fill=None, edgecolor='black', linewidth=2)
      sud_est = plt.Polygon(vertici[5], closed=True, fill=None, edgecolor='black', linewidth=2)
      sud_ovest = plt.Polygon(vertici[6], closed=True, fill=None, edgecolor='black', linewidth=2)

      ax.add_patch(nord)
      ax.add_patch(nord_ovest)
      ax.add_patch(sud)
      ax.add_patch(sud_ovest)
      ax.add_patch(nord_est)
      ax.add_patch(sud_est)

      ax.add_patch(faulty)

      # Plot the random points inside the hexagon with correct colors
      for i in range(self.num_users):
        cell_assigned = self.user_assignments[i]
        cur_color = self.cells[cell_assigned]['color']
        if cur_color == 'tab:blue':
          south_users.append(self.users[i])
        plt.scatter(self.users[i,0], self.users[i,1],
                    color=cur_color, marker='o', s=6)


      # Plotting the blue solid triangles
      for i in range(len(self.BS_pos)):
        ax.scatter(self.BS_pos[i][0],
                  self.BS_pos[i][1],
                  color='black', marker='^',
                  edgecolor='black',
                  s=150)

      '''
      Add BS text
      '''
      # BS 1
      ax.text(self.BS_pos[0][0]-100,
                self.BS_pos[0][1]-300,
                f"BS$_{1}$")
      # BS 2
      ax.text(self.BS_pos[1][0]-50,
                self.BS_pos[1][1]-300,
                f"BS$_{2}$")

      # BS 3
      ax.text(self.BS_pos[2][0]+50,
                self.BS_pos[2][1],
                f"BS$_{3}$")

      # BS 4
      ax.text(self.BS_pos[3][0]-400,
                self.BS_pos[3][1]-170,
                f"BS$_{4}$")


      '''
      Add arrows for the antennas
      '''

      # South Cell
      color = self.cells[0]['color']
      index = 1
      ax.arrow(self.BS_pos[1][0], self.BS_pos[1][1], -650, 0, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2,
               label=f'C$_{1}$')

      # South-East
      color = self.cells[1]['color']
      index = 1
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], 350, 350*3/2, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{2}$')

      # South-West
      color = self.cells[2]['color']
      index = 0
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], 350, 350*3/2, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{3}$')

      # North
      color = self.cells[3]['color']
      index = 3
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], 350, 350*3/2, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{4}$')

      # North-East
      color = self.cells[4]['color']
      index = 2
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], -350, -(350*3/2),
               head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{5}$')

      # North-West
      color = self.cells[5]['color']
      index = 3
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], -650, 0, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{6}$')

      ax.plot()

      #ax.set_aspect('equal', 'datalim')
      #plt.title('Cellular Network')
      plt.xlabel('x [m]')
      plt.ylabel('y [m]')
      plt.xlim([self.BS_rotta[0]-1500,self.BS_rotta[0]+2200])
      plt.ylim([self.BS_rotta[1]-2600,self.BS_rotta[1]+1900])
      plt.legend(fontsize=9.4, ncol=3)
      plt.savefig('federated_assignment.pdf',bbox_inches='tight')

      return np.array(south_users)

    def plot_hexagon_during_fault(self):
      # Plotting with matplotlib.
      fig, ax = plt.subplots(figsize=(5.1,6))
      plt.grid(False)

      vertici = self.vertici

      # Create Polygon patches from the vertices.
      faulty = plt.Polygon(vertici[0], closed=True, facecolor='red',
                          alpha=0.3,
                          edgecolor='black',
                          linewidth=2)
      nord = plt.Polygon(vertici[1], closed=True,fill=None, edgecolor='black', linewidth=2)
      nord_est = plt.Polygon(vertici[2], closed=True,fill=None,
                            edgecolor='black', linewidth=2)
      nord_ovest = plt.Polygon(vertici[3], closed=True, fill=None, edgecolor='black', linewidth=2)
      sud = plt.Polygon(vertici[4], closed=True, fill=None, edgecolor='black', linewidth=2)
      sud_est = plt.Polygon(vertici[5], closed=True, fill=None, edgecolor='black', linewidth=2)
      sud_ovest = plt.Polygon(vertici[6], closed=True, fill=None, edgecolor='black', linewidth=2)

      ax.add_patch(nord)
      ax.add_patch(nord_ovest)
      ax.add_patch(sud)
      ax.add_patch(sud_ovest)
      ax.add_patch(nord_est)
      ax.add_patch(sud_est)

      ax.add_patch(faulty)

      # Plot the random points inside the hexagon
      for i in range(self.num_users-1):
        plt.scatter(self.users[i,0], self.users[i,1],
                    color='grey', marker='o', s=6)
      ax.scatter(self.users[i+1,0], self.users[i+1,1], color='grey',
                  marker='o', s=6,
                  label='Users')

      # Plotting the black solid triangles for the Base Stations
      for i in range(len(self.BS_pos)):
        ax.scatter(self.BS_pos[i][0],
                  self.BS_pos[i][1],
                  color='black', marker='^',
                  edgecolor='black',
                  s=150)

      # BS 1
      ax.text(self.BS_pos[0][0]-100,
                self.BS_pos[0][1]-300,
                f"BS$_{1}$")
      # BS 2
      ax.text(self.BS_pos[1][0]-50,
                self.BS_pos[1][1]-300,
                f"BS$_{2}$")

      # BS 3
      ax.text(self.BS_pos[2][0]+50,
                self.BS_pos[2][1],
                f"BS$_{3}$")

      # BS 4
      ax.text(self.BS_pos[3][0]-400,
                self.BS_pos[3][1]-170,
                f"BS$_{4}$")

      '''
      Add arrows for the antennas
      '''

      # South Cell
      color = self.cells[0]['color']
      index = 1
      ax.arrow(self.BS_pos[1][0], self.BS_pos[1][1], -650, 0, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2,
               label=f'C$_{1}$')

      # South-East
      color = self.cells[1]['color']
      index = 1
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], 350, 350*3/2, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{2}$')

      # South-West
      color = self.cells[2]['color']
      index = 0
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], 350, 350*3/2, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{3}$')

      # North
      color = self.cells[3]['color']
      index = 3
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], 350, 350*3/2, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{4}$')

      # North-East
      color = self.cells[4]['color']
      index = 2
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], -350, -(350*3/2),
               head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{5}$')

      # North-West
      color = self.cells[5]['color']
      index = 3
      ax.arrow(self.BS_pos[index][0], self.BS_pos[index][1], -650, 0, head_width=100.0,
               head_length=50.0, fc=color, ec=color,linewidth=2, label=f'C$_{6}$')

      ax.plot()

      #ax.set_aspect('equal', 'datalim')
      #plt.title('Cellular Network')
      plt.xlabel('x [m]')
      plt.ylabel('y [m]')
      plt.xlim([self.BS_rotta[0]-1500,self.BS_rotta[0]+2200])
      plt.ylim([self.BS_rotta[1]-2600,self.BS_rotta[1]+1900])
      plt.legend(fontsize=9.4, ncol = 4)
      plt.savefig('centralized_fault.pdf',bbox_inches='tight')

    def create_hexagon(self, radius, vertex, anchored_idx=0, anchored_angle=0):
      """
      Plots a regular hexagon with a given circumradius so that a specific vertex
      (identified by anchored_idx, an integer in 0,...,5)
      is placed at the provided 'vertex' coordinate.

      Parameters:
        radius         : float, the circumradius of the hexagon.
        vertex         : tuple, the (x, y) coordinates where the anchored vertex should lie.
        anchored_idx   : int, which vertex (0 to 5) should be at the specified coordinate.
                        Default is 0.
        anchored_angle : float, the angle (in radians) that the vector from the center
                        to the anchored vertex should make with the positive x-axis.
                        For example, 0 means the anchored vertex points horizontally to the right.
                        Default is 0.
      """

      # Calculate the hexagon's center. Since the anchored vertex should be:
      # vertex = center + radius * [cos(anchored_angle), sin(anchored_angle)],
      # we invert the formula to get the center.
      cx = vertex[0] - radius * np.cos(anchored_angle)
      cy = vertex[1] - radius * np.sin(anchored_angle)
      center = (cx, cy)

      # Determine the overall rotation offset.
      # We want that for the anchored index, the angle is exactly anchored_angle.
      # Note: A regular hexagon has its vertices separated by 2pi/6.
      rotation = anchored_angle - anchored_idx * (2 * np.pi / 6)

      # Compute all six vertex positions.
      vertices = []
      for i in range(6):
          angle = rotation + i * (2 * np.pi / 6)
          x = cx + radius * np.cos(angle)
          y = cy + radius * np.sin(angle)
          vertices.append((x, y))

      return vertices

    def random_points_in_hexagon(self):
        cx, cy = self.center
        hex_radius = self.hexagon_size

        # Hexagon vertices (centered at center point)
        hexagon = np.array([
            (np.cos(2 * np.pi * i / 6), np.sin(2 * np.pi * i / 6))
            for i in range(6)
        ]) * hex_radius + np.array([cx, cy])

        # Bounding box for the hexagon
        min_x, max_x = cx - hex_radius, cx + hex_radius
        min_y, max_y = cy - np.sqrt(3) / 2 * hex_radius, cy + np.sqrt(3) / 2 * hex_radius

        points = []
        while len(points) < self.num_users:
            # Generate random point within bounding box
            x = np.random.uniform(min_x, max_x)
            y = np.random.uniform(min_y, max_y)

            # Check if point is inside the hexagon
            if self.is_inside_hexagon((x, y), hexagon):
                points.append((x, y))

        return np.array(points)

    def is_inside_hexagon(self, point, hexagon):
        x, y = point
        # Check if the point is inside using the half-plane method
        for i in range(6):
            x1, y1 = hexagon[i]
            x2, y2 = hexagon[(i + 1) % 6]
            if (x - x1) * (y2 - y1) - (y - y1) * (x2 - x1) > 0:
                return False
        return True

    def create_cells(self):

      broken_BS_pos = self.BS_rotta
      size = self.hexagon_size

      vertici_cella_rotta = self.create_hexagon(radius=size, vertex=broken_BS_pos,
                                          anchored_idx=0,
                                          anchored_angle=2*np.pi/3)

      esagono_nord = self.create_hexagon(radius=size, vertex=broken_BS_pos,
                                    anchored_idx=0,
                                    anchored_angle=-2*np.pi/3)

      esagono_nord_ovest = self.create_hexagon(radius=size, vertex=broken_BS_pos,
                                          anchored_idx=0,
                                          anchored_angle=0)

      next_vertex = vertici_cella_rotta[1]

      esagono_sud_ovest = self.create_hexagon(radius=size, vertex=next_vertex,
                                        anchored_idx=0,
                                        anchored_angle=np.pi/3)

      next_vertex = vertici_cella_rotta[2]

      esagono_sud = self.create_hexagon(radius=size, vertex=next_vertex,
                                  anchored_idx=0,
                                  anchored_angle=2*np.pi/3)

      next_vertex = vertici_cella_rotta[3]

      esagono_sud_est = self.create_hexagon(radius=size, vertex=next_vertex,
                                      anchored_idx=0,
                                      anchored_angle=np.pi)

      next_vertex = vertici_cella_rotta[4]

      esagono_nord_est = self.create_hexagon(radius=size, vertex=next_vertex,
                                        anchored_idx=0,
                                        anchored_angle=-2*np.pi/3)

      BS_1_pos = esagono_sud_ovest[3]
      BS_2_pos = esagono_sud[4]
      BS_3_pos = esagono_nord_est[3]

      cells = []

      # Create Cells

      # South
      S_cell = {}
      S_cell['BS_position'] = BS_2_pos
      S_cell['beam'] = 180
      S_cell['color'] = 'tab:blue'
      S_cell['name'] = 'South'

      # South-East
      SE_cell = {}
      SE_cell['BS_position'] = BS_2_pos
      SE_cell['beam'] = 60
      SE_cell['color'] = 'tab:orange'
      SE_cell['name'] = 'South-East'

      # South-West
      SW_cell = {}
      SW_cell['BS_position'] = BS_1_pos
      SW_cell['beam'] = 60
      SW_cell['color'] = 'tab:green'
      SW_cell['name'] = 'South-West'

      # North
      N_cell = {}
      N_cell['BS_position'] = broken_BS_pos
      N_cell['beam'] = 60
      N_cell['color'] = 'tab:red'
      N_cell['name'] = 'North'

      # North-East
      NE_cell = {}
      NE_cell['BS_position'] = BS_3_pos
      NE_cell['beam'] = 240
      NE_cell['color'] = 'tab:purple'
      NE_cell['name'] = 'North-East'

      # North-West
      NW_cell = {}
      NW_cell['BS_position'] = broken_BS_pos
      NW_cell['beam'] = 180
      NW_cell['color'] = 'tab:brown'
      NW_cell['name'] = 'North-West'

      vertici = [vertici_cella_rotta,
                esagono_nord,
                esagono_nord_est,
                esagono_nord_ovest,
                esagono_sud,
                esagono_sud_est,
                esagono_sud_ovest]

      cells = [S_cell, SE_cell, SW_cell, N_cell, NE_cell, NW_cell]

      return cells, vertici

    def normalize_RSRP(self, RSRP):

      return (RSRP - self.RSRP_min)/(self.RSRP_max - self.RSRP_min)

    def compute_3gpp_path_loss(self, d):
      """
      Computes the 3D Urban Macro Path Loss based on 3GPP TR 38.901.

      Parameters:
      d    : float or np.array - 2D distance between transmitter and receiver (in meters)
      f_c  : float - Carrier frequency (in GHz)
      h_UT : float - User terminal height (in meters), default is 1.5m
      h_BS : float - Base station height (in meters), default is 25m

      Returns:
      float or np.array - Path loss (in dB)
      """
      # 3D Distance
      d3D = np.sqrt(d**2 + (self.h_BS-self.h_UE)**2)

      # LOS Path Loss
      PL_LOS = 28 + 22 * np.log10(d3D) + 20 * np.log10(self.freq_GHz)

      # NLOS Path Loss
      PL_NLOS = 13.54 + 39.08 * np.log10(d3D) + 20 * np.log10(self.freq_GHz) - \
                     0.6 * (self.h_UE - 1.5)


      # Apply height correction if user terminal height is outside the range
      height_correction = -np.minimum(0, 20 * np.log10(self.h_UE / 1.5))

      PL = np.maximum(PL_LOS, PL_NLOS) + height_correction

      return PL

    def free_space_path_loss(self, d):
        """Compute the free-space path loss (FSPL) in dB."""
        """ FSPL = (4 pi f d/c)^2 """

        fspl = 20 * np.log10(d) + 20 * np.log10(self.freq_hz) + \
               20 * np.log10(4*np.pi/3e8)

        return fspl

    def compute_azimuth_gain(self, cell_id, user_id):

      bs_pos = self.cells[cell_id]['BS_position']
      phi_0 = self.cells[cell_id]['beam']
      user_pos = self.users[user_id,:]

      x_UE = user_pos[0]
      y_UE = user_pos[1]
      x_BS = bs_pos[0]
      y_BS = bs_pos[1]

      phi = np.arctan2(y_UE-y_BS, x_UE-x_BS)

      phi = np.rad2deg(phi)

      if phi < 0:
        phi = 360 + phi

      phi_delta = abs(phi-phi_0)

      if phi_delta > 180:
        phi_delta = 360 - phi_delta

      gain = self.G_max - min(12 * (phi_delta/self.HPBW_h)**2 , self.SSL_h)

      return gain

    def compute_RSRP(self, cell_id, user_id):
        """Compute the RSRP (in dBm) based on FSPL and a given CELL."""

        bs_pos = self.cells[cell_id]['BS_position']

        cell_name = self.cells[cell_id]['name']

        user_pos = self.users[user_id,:]

        distance = np.linalg.norm(np.array(bs_pos) - np.array(user_pos))

        if distance == 0:
            return -np.inf  # Avoid log(0) error


        complex_path_loss = self.compute_3gpp_path_loss(distance)

        #fspl = self.free_space_path_loss(distance)

        path_loss_db = complex_path_loss


        # Compute azimuth gain based on relative position between the antenna
        gain_tx_db = self.compute_azimuth_gain(cell_id, user_id)

        received_power_dbm = self.tx_power_dbm + gain_tx_db + self.gain_rx_db - path_loss_db

        #print(f"Cell {cell_name} UE {user_id+1} ---> RSRP: {received_power_dbm}")

        #time.sleep(10)

        return received_power_dbm

    def compute_snr(self, bs_id, user_id):
        """Compute the SNR based on FSPL and given BS."""

        """Thermal noise is given at T = 293 K temperature"""

        RSRP = self.compute_RSRP(bs_id, user_id)

        '''
        Be careful: thermal noise = k_B * T * B
        The bandwidth is not the full bandwidth, since
        the base station reserve only a portion of the channel to the user
        '''
        #

        noise_power_dbm = 10 * np.log10(1.38e-23 * 1000) + \
                           10 * np.log10(self.Kelvin) +  \
                           10 * np.log10(self.prb_bandwidth_hz)  # Thermal noise

        snr_db = RSRP - noise_power_dbm

        #print(f"RSRP: {RSRP}")
        #print(f"Thermal Noise: {noise_power_dbm}")
        #print(f"SNR dB: {snr_db}")
        #time.sleep(10)

        return snr_db

    def prb_needed(self, user_qos, snr_db):
        """Estimate PRBs required based on Shannon capacity approximation."""
        snr_linear = 10**(snr_db / 10)

        # Compute spectral efficiency
        sp_eff = np.log2(1 + snr_linear)

        # Required bandwidth
        req_bw_hz = user_qos * 1e6 / sp_eff

        req_prb = int(np.ceil(req_bw_hz / self.prb_bandwidth_hz))

        #print(f"SNR   {snr_db}  QoS {user_qos}   PRBs: {req_prb}")
        #time.sleep(5)

        return req_prb

    def action2cmask(self, a):

      c_mask = np.zeros(self.n_actions)

      c_mask[a] = 1

      c_mask = tuple(c_mask)

      return c_mask

    def computeReward(self, action):

      '''
      The goal is to find a trade off between choosing the highest RSRP
      and keeping the load (at time k) low as possible

      The highest instantaneous reward is r(k) = 0

      '''

      # Weight on RSRP
      alpha = 1.0

      # Weight on Load
      beta = 1.0

      reward = alpha*(self.norm_RSRPs[action] - np.max(self.norm_RSRPs)) - \
               beta*(self.bs_load[action] - np.min(self.bs_load))

      return reward

    def step(self, action):
        """Perform a step where the next user requests connectivity."""

        # Compute connection mask
        c_mask = self.action2cmask(action)

        # Update the assignment vector (for plotting)
        self.user_assignments.append(action)

        # Call reward function before updating the BS load dynamics
        reward = self.computeReward(action)

        snrs = np.array([self.compute_snr(bs_id, self.current_user) for bs_id in range(self.n_actions)])
        prbs_needed = np.array([self.prb_needed(self.cur_qos, snr) for snr in snrs])

        # Increment the load of the base station who is taking care of the user
        # Obtain second observation at time k+1
        for i in range(self.n_actions):
          self.bs_load[i] += c_mask[i]*(prbs_needed[i]/self.total_prbs)

          self.bs_load[i] = min(self.bs_load[i], 1.0)

        '''
        Here we prepare to provide the next observation to the DRL agent
        '''

        # Take the next user
        self.current_user += 1

        # Episode termination condition
        self.ter = self.current_user >= self.num_users

        if self.ter == True:

          obs = np.concatenate(([self.cur_qos_level],
                                self.bs_load,
                                self.norm_RSRPs))
          info = self.RSRPs

          return obs, reward, self.ter, self.tru, info

        # take the next user

        self.cur_qos = self.user_qos[self.current_user]
        self.cur_qos_level = self.qos_levels[self.current_user]

        self.RSRPs = np.array([self.compute_RSRP(bs_id, self.current_user) for bs_id in range(self.n_actions)])

        self.norm_RSRPs = self.normalize_RSRP(self.RSRPs)

        '''
        If needed, add here trunction condition

        self.tru = ...
        '''

        # Observations for each BS: (user QoS, BS load, RSRP)
        obs = np.concatenate(([self.cur_qos_level],
                              self.bs_load,
                              self.norm_RSRPs))

        # de-normalized RSRPs
        info = self.RSRPs

        return obs, reward, self.ter, self.tru, info

    def reset(self, seed=None):
        """Reset the environment for a new episode."""

        # Set seed for a specific scenario for comparison in the paper
        if seed != None:
          np.random.seed(seed)

        # Extract 6 Gaussian random samples
        self.bs_load = np.random.normal(self.mu, self.sigma, self.n_actions)

        self.current_user = 0
        self.ter = False
        self.tru = False

        # Plot users as simple grey points
        self.users = self.random_points_in_hexagon()

        self.user_assignments = []

        self.user_qos = np.random.choice(self.datarates, self.num_users)

        # Map qos values to corresponding indices - to be used as first observation
        self.qos_levels = np.array([self.datarates.index(q) for q in self.user_qos])

        self.cur_qos = self.user_qos[self.current_user]
        self.cur_qos_level = self.qos_levels[self.current_user]

        self.RSRPs = np.array([self.compute_RSRP(bs_id, self.current_user) for bs_id in range(self.n_actions)])

        self.norm_RSRPs = self.normalize_RSRP(self.RSRPs)

        obs = np.concatenate(([self.cur_qos_level],
                              self.bs_load,
                              self.norm_RSRPs))

        info = self.RSRPs

        return obs, info

"""## Compute empirically RSRP_min e RSRP_max for state normalization"""

env = CellularNetworkEnv(BS_power=10, num_users=50000)

obs, info = env.reset()

n_actions = env.n_actions

done = False
step = 0

RSRP_database = []

for i in range(n_actions):
  RSRP_database.append(info[i])

while not done:

    action = np.random.randint(n_actions)

    obs, rew, ter, tru, info = env.step(action)

    for i in range(n_actions):
      RSRP_database.append(info[i])

    done = ter or tru

    step+=1

print(f"Min RSRP: {min(RSRP_database)}")
print(f"Max RSRP: {max(RSRP_database)}")

"""## Environment Scenario Test"""

# Test the environment dynamics
env = CellularNetworkEnv(BS_power=10, num_users=5)

n_actions = env.n_actions
n_states = env.n_states

obs, info = env.reset(seed = 50)

env.plot_hexagon_during_fault()

"""# Benchmark Strategies

## Random
"""

# Test the environment dynamics

env = CellularNetworkEnv(BS_power=10, num_users=120)

n_actions = env.n_actions
n_states = env.n_states

obs, info = env.reset(seed = 201)
done = False
BS_load_random = np.zeros((n_actions , env.num_users + 1))
step = 0

BS_load_random[:,step] = obs[1:7]

RSRP = []

score = 0

while not done:

    action = np.random.randint(n_actions)

    real_RSRP = info[action]
    RSRP.append(real_RSRP)

    obs, rew, ter, tru, info = env.step(action)

    score+=rew

    done = ter or tru

    step+=1
    BS_load_random[:,step] = obs[1:7]


print(f"Final Score: {score}")

print(f"Avg RSRP: {np.mean(RSRP)}")

# Plot results about BS_loads
plt.figure(figsize=(6,5))
for i in range(n_actions):
    plt.plot(100*BS_load_random[i,:], label=f'C$_{i+1}$',
             linewidth=2)

plt.grid(True)
plt.title('Random Assignment Strategy')
plt.legend(ncol=3)
plt.xlabel('Time Step')
plt.ylabel('Load [%]')
plt.ylim([0, 110])
plt.xlim([0, 120])

env.plot_hexagon_D3QN()

"""## Max RSRP"""

# Test the environment dynamics
env = CellularNetworkEnv(BS_power=10, num_users=120)

obs, _ = env.reset(seed = 201)
done = False
BS_load_MR = np.zeros((n_actions,env.num_users+1))
step = 0

BS_load_MR[:,step] = obs[1:7]

score = 0

RSRP = []

while not done:

    # Choose the current agent
    RSRPs_cur = obs[7:13]
    ping_BS = np.argmax(RSRPs_cur)

    real_RSRP = info[ping_BS]
    RSRP.append(real_RSRP)

    obs, rew, ter, tru, info = env.step(ping_BS)
    score+=rew
    done = ter or tru
    step+=1

    BS_load_MR[:,step] = obs[1:7]

# Print results on the selected KPIs
print(f"Avg RSRP: {np.mean(RSRP)}")
print(f"Min RSRP: {min(RSRP)}")
print(f"MAX RSRP: {max(RSRP)}")
print(f"Max final load: {100*np.max(BS_load_MR[:,-1])}")
print(f"Mean final load: {100*np.mean(BS_load_MR[:,-1])}")
print(f"Var final load: {np.var(100*BS_load_MR[:,-1])}")
print(f"Final Score: {score}")

# Plot results about BS_loads
plt.figure(figsize=(6,6))
for i in range(n_actions):
    plt.plot(100*BS_load_MR[i,:], label=f'C$_{i+1}$',
             linewidth=2)
plt.grid(True)
plt.legend(loc='upper left', ncol=3)
plt.xlabel('Time Step')
plt.ylabel('Load [%]')
plt.ylim([0, 100])
plt.xlim([0, 120])
plt.savefig('MAX_RSRP_loads.pdf',bbox_inches='tight')

"""## Least Loaded"""

# Test the environment dynamics
env = CellularNetworkEnv(BS_power=10, num_users=120)

obs, info = env.reset(seed = 201)
done = False
BS_load_LL = np.zeros((n_actions,env.num_users+1))
step = 0
score = 0
BS_load_LL[:,step] = obs[1:7]
RSRP = []

while not done:

    ping_BS = np.argmin(obs[1:7])
    real_RSRP = info[ping_BS]
    RSRP.append(real_RSRP)

    obs, rew, ter, tru, info = env.step(ping_BS)
    score+=rew
    done = ter or tru
    step+=1
    BS_load_LL[:,step] = obs[1:7]

# Print results on the selected KPIs
print(f"Avg RSRP: {np.mean(RSRP)}")
print(f"Min RSRP: {min(RSRP)}")
print(f"MAX RSRP: {max(RSRP)}")
print(f"Max final load: {100*np.max(BS_load_LL[:,-1])}")
print(f"Mean final load: {100*np.mean(BS_load_LL[:,-1])}")
print(f"Var final load: {np.var(100*BS_load_LL[:,-1])}")
print(f"Final Score: {score}")

# Plot results about BS_loads
plt.figure(figsize=(6,6))
for i in range(n_actions):
    plt.plot(100*BS_load_LL[i,:], label=f'C$_{i+1}$',
             linewidth=2)
plt.grid(True)
plt.legend(loc='upper left', ncol=3)
plt.xlabel('Time Step')
plt.ylabel('Load [%]')
plt.ylim([0, 100])
plt.xlim([0, 120])
plt.savefig('least_loaded_loads.pdf',bbox_inches='tight')

"""# Training D3QN

## Agents initialization
"""

# Initialize 6 different agents
'''
Define the number of users to be used within each episode.
Pay attention: this number corresponds to the number of steps
until terminating each episode
'''

env = CellularNetworkEnv(BS_power=10, num_users=120)

# State and action spaces
n_states = env.n_states
n_actions = env.n_actions

# Create three D3QN Agents, one per each BS
agents = [Agent(lr=5e-4, gamma=0.99,
              n_actions=n_actions,
              batch_size=64,
              input_dims=[n_states],
              fc1_dims = 32,
              fc2_dims = 32,
              replace=500) for _ in range(n_actions)]

"""## Epsilon-Greedy Schedule"""

def epsilon_schedule(n_games, exploration_games,
                     exploitation_games, min_epsilon):
    # Linear decay range
    decay_games = n_games - exploration_games - exploitation_games

    # Epsilon schedule
    eps_history = []

    # 1. Constant exploration phase
    eps_history.extend([1.0] * exploration_games)

    # 2. Linear decay phase
    eps_history.extend(np.linspace(1.0, min_epsilon, decay_games))

    # 3. Constant minimal exploration phase
    eps_history.extend([min_epsilon] * exploitation_games)

    # Ensure length matches n_games
    return eps_history[:n_games]

'''
Active BS agent policy
At each round, the active base station is the one having the best RSRP
towards the current user
'''

# Number of episodes after which we average D3QN agents' weights
fed_freq = 10

scores, avg_scores = [], []

# Parameters for the epsilon-greedy strategy
n_games = 200                  # Total number of games
exploration_games = 20         # Number of games to keep epsilon = 1
exploitation_games = 20        # Number of games to keep epsilon = 0.01 at the end
min_epsilon = 1e-4             # Minimum epsilon value

# Create local scores
local_scores = np.zeros((n_actions, n_games))

# Generate epsilon schedule
eps_history = epsilon_schedule(n_games, exploration_games, exploitation_games, min_epsilon)

# Plotting epsilon
plt.figure(figsize=(6, 4))
plt.plot(np.linspace(0,n_games,n_games), eps_history,linewidth=2)

# Add colored vertical bands
plt.axvspan(0, exploration_games, color='red', alpha=0.2,
            label='Exploration Zone')
plt.axvspan(exploration_games + (n_games - exploration_games - exploitation_games),
            n_games, color='green', alpha=0.2, label='Exploitation Zone')

#plt.axvline(exploration_games, color='r', linestyle='--', label='End of Exploration Phase')
#plt.axvline(exploration_games + (n_games - exploration_games - final_exploration_games), color='g', linestyle='--', label='End of Decay Phase')
plt.xlabel('Episodes')
plt.ylabel('Epsilon')
#plt.title('Epsilon-Greedy Schedule')
plt.legend(ncol=2,fontsize=9,loc='upper center')
plt.grid(True)
plt.xlim([0,n_games])
plt.savefig('epsilon.pdf',bbox_inches='tight')

'''
Training starts
'''


for i in range(n_games):
  done = False
  score = 0
  observation, _ = env.reset(seed=i)
  step = 0
  while not done:

    # Choose the current agent
    RSRPs_cur = observation[7:13]
    ping_BS = np.argmax(RSRPs_cur)

    action = agents[ping_BS].choose_action(observation, eps_history[i])

    observation_, reward, ter, tru, info = env.step(action)
    done = ter or tru
    agents[ping_BS].store_transition(observation, action, reward, observation_, done)
    agents[ping_BS].learn()

    # Total one
    score+=reward

    # Local one
    local_scores[ping_BS, i] += reward

    # Prepare the next step
    observation = observation_
    step+=1

  scores.append(score)

  if (i+1) % fed_freq == 0:

    print("...fed averaging...")

    eval_models = [agent.q_eval for agent in agents]
    target_models = [agent.q_next for agent in agents]

    federated_average(eval_models)
    federated_average(target_models)
    # Now all models have the same averaged weights

  avg_score = np.mean(scores[-10:])
  avg_scores.append(avg_score)

  print(f"Episode: {i+1}   Avg_score: {avg_score:.2f}    Epsilon: {eps_history[i]:.2f}")

'''
Save rewards for later plotting
'''

np.save('federated_scores.npy', scores)
np.save('local_scores.npy', local_scores)

"""## Plot Total Reward"""

# Plot avg reward history

def moving_average(signal, k):
  avg = []
  for i in range(len(signal)):
    if i < k:
      avg_score = np.mean(signal[:i])
    else:
      avg_score = np.mean(signal[i-k:i])
    avg.append(avg_score)
  return avg

plt.figure(figsize=(7,3))
plt.plot(scores, label='Cumulative Reward')
smoothed_signal = moving_average(scores, 10)
plt.plot(smoothed_signal,label='Moving Average (k=10)')
plt.xlabel('Episode')
plt.ylabel('Training Score')
plt.legend()
plt.xlim([0, n_games])
plt.ylim([-42,0])
plt.grid(True)
plt.savefig('federated_aggregated_reward.pdf',bbox_inches='tight')

"""## Plot local rewards"""

# Create a 2x3 subplot
fig, axes = plt.subplots(2, 3, figsize=(12, 6))

# Plot each row in a subplot
colors = ['tab:blue','tab:orange','tab:green','tab:red',
          'tab:purple','tab:brown']
for i in range(6):
    row = i // 3  # Row index
    col = i % 3   # Column index
    axes[row, col].plot(local_scores[i, :],color = colors[i], alpha = 0.5,
                        label='Cumulative Reward')
    smoothed_signal = moving_average(local_scores[i,:], 10)
    axes[row, col].plot(smoothed_signal, color = colors[i], linewidth=2,
                        label='Moving Average')
    axes[row, col].set_title(f'C$_{i+1}$')
    axes[row, col].set_xlabel('Episode')
    axes[row,col].set_xlim([0, n_games])
    axes[row, col].set_ylim([-12.5,1])
    axes[row, col].grid('True')
    axes[row, col].legend(fontsize=7,loc='lower right')

# Adjust layout for better spacing
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.savefig('local_rewards.pdf',bbox_inches='tight')

"""# Save D3QN Network Weights"""

for i in range(n_actions):
  agents[i].q_eval.save_weights('Federated_C'+str(i+1)+'.weights.h5')

"""# Evaluation D3QN

## Load Weights
"""

for i in range(n_actions):
  agents[i].q_eval.load_weights('Federated_C'+str(i+1)+'.weights.h5')

"""## Test Run"""

# Episode for testing

num_users = 120      # should guarantee that some BS load overcomes the tolerance
BS_power  = 10       # BS power in Watt

env = CellularNetworkEnv(BS_power=BS_power, num_users=num_users)

obs, info = env.reset(seed = 201)

done = False
score = 0
eps_eval = 0.0   # only deterministic actions

BS_load_fed = np.zeros((n_actions, num_users+1))
step = 0
BS_load_fed[:,step] = obs[1:7]

RSRP = []

while not done:
  # Choose the current agent

  RSRPs_cur = obs[7:13]
  ping_BS = np.argmax(RSRPs_cur)

  action = agents[ping_BS].choose_action(obs, eps_eval)

  real_RSRP = info[action]
  RSRP.append(real_RSRP)

  obs_, rew, ter, tru, info = env.step(action)

  done = ter or tru
  score+=rew

  obs = obs_
  step+=1
  BS_load_fed[:,step] = obs[1:7]

# Print results on the selected KPIs
print(f"Avg RSRP: {np.mean(RSRP)}")
print(f"Min RSRP: {min(RSRP)}")
print(f"MAX RSRP: {max(RSRP)}")
print(f"Max final load: {100*np.max(BS_load_fed[:,-1])}")
print(f"Mean final load: {100*np.mean(BS_load_fed[:,-1])}")
print(f"Var final load: {np.var(100*BS_load_fed[:,-1])}")
print(f"Final Score: {score}")

# Plot results about BS_loads
plt.figure(figsize=(6,6))
for i in range(n_actions):
    plt.plot(100*BS_load_fed[i,:],
             label=f'C$_{i+1}$',
             linewidth=2)
plt.grid(True)
plt.legend(loc='upper left', ncol=3)
plt.ylabel('Load [%]')
plt.xlabel('Time step')
plt.xlim([0, num_users])
plt.ylim([0, 100])
plt.savefig('federated_loads.pdf',bbox_inches='tight')

simone_users = env.plot_hexagon_D3QN()

"""# Per Simone

"""

BS_2_pos = np.array([1050, -319])

np.save('BS_2_pos.npy',BS_2_pos)
np.save('blue_users.npy',simone_users)


print(BS_2_pos)
print(simone_users)